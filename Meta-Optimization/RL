# æ­¥éª¤ 0: å®‰è£…å¿…è¦çš„åº“
# å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£…è¿™äº›åº“ï¼Œè¯·å…ˆè¿è¡Œè¿™è¡Œå‘½ä»¤
# pip install sentence-transformers numpy torch

import numpy as np
from sentence_transformers import SentenceTransformer

def parse_prompt(raw_prompt: str) -> dict:
    """
    ä¸€ä¸ªç®€åŒ–çš„è§£æå‡½æ•°ï¼Œå°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–å­—å…¸ã€‚
    åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™ä¸€æ­¥å¯èƒ½éœ€è¦ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ã€å…³é”®è¯åˆ†å‰²ï¼Œ
    ç”šè‡³è°ƒç”¨ä¸€ä¸ªLLMæ¥åšç»“æ„åŒ–è§£æã€‚
    """
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç›´æ¥æ‰‹åŠ¨åˆ›å»ºè¿™ä¸ªç»“æ„ã€‚
    structured_prompt = {
        "role": "ä½ æ˜¯ä¸€åèµ„æ·±è¥é”€æ–‡æ¡ˆã€‚",
        "task": "ä¸ºä¸€æ¬¾åä¸ºâ€˜æ˜Ÿå°˜å’–å•¡â€™çš„æ–°å“å†™ä¸‰æ¡å®£ä¼ æ ‡è¯­ã€‚",
        "constraints": [
            "æ¯æ¡ä¸è¶…è¿‡15ä¸ªå­—",
            "é£æ ¼è¦æ–‡è‰ºä¸”æœ‰æƒ³è±¡åŠ›"
        ],
        "examples": [],
        "format": ""
    }
    return structured_prompt

def create_state_vector(raw_prompt: str, metadata: dict, model: SentenceTransformer) -> np.ndarray:
    """
    å°†åŸå§‹æç¤ºè¯å’Œå…ƒæ•°æ®è½¬æ¢ä¸ºä¸€ä¸ªå®Œæ•´çš„çŠ¶æ€å‘é‡ã€‚

    Args:
        raw_prompt (str): åŸå§‹çš„æç¤ºè¯æ–‡æœ¬ã€‚
        metadata (dict): åŒ…å«é€‚åº”åº¦ç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å­—å…¸ã€‚
        model (SentenceTransformer): ç”¨äºç¼–ç çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

    Returns:
        np.ndarray: æœ€ç»ˆæ‹¼æ¥å¥½çš„çŠ¶æ€å‘é‡ã€‚
    """
    print("--- æ­¥éª¤ 1: è§£æåŸå§‹æç¤ºè¯ ---")
    structured_prompt = parse_prompt(raw_prompt)
    print("ç»“æ„åŒ–æç¤ºè¯:")
    print(structured_prompt)
    print("-" * 20)

    print("--- æ­¥éª¤ 2: ç‹¬ç«‹ç¼–ç æ–‡æœ¬éƒ¨åˆ† ---")
    embedding_dim = model.get_sentence_embedding_dimension()

    # ç¼–ç è§’è‰²å’Œä»»åŠ¡
    role_vector = model.encode(structured_prompt['role'])
    task_vector = model.encode(structured_prompt['task'])
    print(f"è§’è‰²å‘é‡ç»´åº¦: {role_vector.shape}")
    print(f"ä»»åŠ¡å‘é‡ç»´åº¦: {task_vector.shape}")

    # ç¼–ç çº¦æŸåˆ—è¡¨ï¼ˆå–å¹³å‡å€¼ï¼‰
    if structured_prompt['constraints']:
        constraint_vectors = model.encode(structured_prompt['constraints'])
        avg_constraint_vector = np.mean(constraint_vectors, axis=0)
    else:
        avg_constraint_vector = np.zeros(embedding_dim) # ä½¿ç”¨é›¶å‘é‡å ä½
    print(f"å¹³å‡çº¦æŸå‘é‡ç»´åº¦: {avg_constraint_vector.shape}")
    
    # å¯¹å…¶ä»–å­—æ®µï¼ˆå¦‚examples, formatï¼‰ä¹Ÿå¯ä»¥æ‰§è¡Œç±»ä¼¼æ“ä½œ
    # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾å®ƒä»¬ä¸ºç©ºï¼Œå¹¶ç”¨é›¶å‘é‡è¡¨ç¤º
    avg_example_vector = np.zeros(embedding_dim)
    format_vector = np.zeros(embedding_dim)
    print("-" * 20)

    print("--- æ­¥éª¤ 3: æå–å¹¶è§„èŒƒåŒ–ä¸Šä¸‹æ–‡ç‰¹å¾ ---")
    # æ³¨æ„ï¼šåœ¨å®é™…è®­ç»ƒå¾ªç¯ä¸­ï¼Œæ•°å€¼å‹ç‰¹å¾åº”è¯¥è¢«è§„èŒƒåŒ–ï¼ˆä¾‹å¦‚ç¼©æ”¾åˆ°0-1èŒƒå›´ï¼‰
    context_feature_vector = np.array([
        metadata.get('fitness', 0.0),
        metadata.get('token_count', 0),
        metadata.get('num_constraints', len(structured_prompt.get('constraints', []))),
        metadata.get('iterations_stuck', 0)
    ])
    print(f"ä¸Šä¸‹æ–‡ç‰¹å¾å‘é‡: {context_feature_vector}")
    print(f"ä¸Šä¸‹æ–‡ç‰¹å¾å‘é‡ç»´åº¦: {context_feature_vector.shape}")
    print("-" * 20)

    print("--- æ­¥éª¤ 4: æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†ï¼Œå½¢æˆæœ€ç»ˆçŠ¶æ€å‘é‡ ---")
    all_vectors = [
        role_vector,
        task_vector,
        avg_constraint_vector,
        avg_example_vector,
        format_vector,
        context_feature_vector
    ]
    
    final_state_vector = np.concatenate(all_vectors)
    print(f"æœ€ç»ˆçŠ¶æ€å‘é‡çš„æ€»ç»´åº¦: {final_state_vector.shape}")
    print("-" * 20)

    return final_state_vector

# ================== ä¸»ç¨‹åºå…¥å£ ==================
if __name__ == "__main__":
    # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ (è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼Œåªéœ€è¦åŠ è½½ä¸€æ¬¡)
    print("æ­£åœ¨åŠ è½½ SentenceTransformer æ¨¡å‹...")
    # 'all-MiniLM-L6-v2' æ˜¯ä¸€ä¸ªè½»é‡ä¸”é«˜æ•ˆçš„æ¨¡å‹ï¼Œè¾“å‡º384ç»´å‘é‡
    encoder_model = SentenceTransformer('all-MiniLM-L6-v2')
    print("æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")
    print("=" * 30)

    # 2. å‡†å¤‡è¾“å…¥æ•°æ®
    # ä½ çš„ä¸»è¿­ä»£ç®—æ³•å‘ç°è¿™ä¸ªæç¤ºè¯é™·å…¥äº†å±€éƒ¨æœ€ä¼˜
    sample_raw_prompt = "ä½ æ˜¯ä¸€åèµ„æ·±è¥é”€æ–‡æ¡ˆã€‚ä¸ºä¸€æ¬¾åä¸ºâ€˜æ˜Ÿå°˜å’–å•¡â€™çš„æ–°å“å†™ä¸‰æ¡å®£ä¼ æ ‡è¯­ã€‚è¦æ±‚ï¼šæ¯æ¡ä¸è¶…è¿‡15ä¸ªå­—ï¼Œé£æ ¼è¦æ–‡è‰ºä¸”æœ‰æƒ³è±¡åŠ›ã€‚"
    
    # ç›¸å…³çš„ä¸Šä¸‹æ–‡å…ƒæ•°æ®
    sample_metadata = {
        "fitness": 0.92,
        "token_count": 68,
        "iterations_stuck": 5
    }

    # 3. è°ƒç”¨å‡½æ•°ç”Ÿæˆæœ€ç»ˆçš„çŠ¶æ€å‘é‡
    final_vector = create_state_vector(
        raw_prompt=sample_raw_prompt,
        metadata=sample_metadata,
        model=encoder_model
    )

    print("\nâœ… ç”Ÿæˆå®Œæ¯•ï¼")
    print(f"æœ€ç»ˆçŠ¶æ€å‘é‡çš„å‰10ä¸ªå€¼: {final_vector[:10]}")
    print(f"è¿™ä¸ªç»´åº¦ä¸º {final_vector.shape[0]} çš„å‘é‡ï¼Œç°åœ¨å¯ä»¥ä½œä¸ºRLä»£ç†ç¥ç»ç½‘ç»œçš„è¾“å…¥äº†ã€‚")



import random
import copy

# ==============================================================================
# æ­¥éª¤ 1: ä¸ºåŠ¨ä½œå‡†å¤‡â€œç´ æåº“â€
# è¿™äº›åº“ä¸ºåŠ¨ä½œå‡½æ•°æä¾›äº†éšæœºé€‰æ‹©çš„å†…å®¹ï¼Œä½¿å…¶æ›´åŠ åŠ¨æ€ã€‚
# ==============================================================================

ROLE_LIBRARY = [
    "You are a world-renowned historian specializing in the Renaissance.",
    "You are a cutting-edge astrophysicist from MIT.",
    "You are a Michelin 3-star chef with expertise in molecular gastronomy.",
    "You are a cynical but brilliant detective from a noir film."
]

CONSTRAINT_LIBRARY = [
    "Explain your reasoning step-by-step.",
    "The final answer must be a single paragraph.",
    "Avoid technical jargon and use simple language.",
    "Output the result in a JSON format with keys 'item' and 'description'.",
    "Do not mention your own identity as an AI model."
]

EXAMPLE_LIBRARY = [
    {"input": "Company: Apple Inc.", "output": "Industry: Technology"},
    {"input": "Company: Toyota", "output": "Industry: Automotive"}
]

TONE_LIBRARY = [
    "in a formal and professional tone",
    "in a friendly and conversational tone",
    "in a witty and slightly sarcastic tone",
    "in a way that a complete beginner can understand"
]


# ==============================================================================
# æ­¥éª¤ 2: å®ç°æ¯ä¸ªå…·ä½“çš„åŠ¨ä½œå‡½æ•°
# æ¯ä¸ªå‡½æ•°éƒ½æ¥æ”¶ä¸€ä¸ªç»“æ„åŒ–æç¤ºè¯å­—å…¸ï¼Œå¹¶è¿”å›ä¸€ä¸ªä¿®æ”¹åçš„æ–°å­—å…¸ã€‚
# ä½¿ç”¨ deepcopy æ¥ç¡®ä¿æˆ‘ä»¬ä¸ä¼šæ„å¤–ä¿®æ”¹åŸå§‹æç¤ºè¯ã€‚
# ==============================================================================

def paraphrase_task(prompt: dict) -> dict:
    """åŠ¨ä½œ1: æ ¸å¿ƒä»»åŠ¡é‡Šä¹‰ (æ¨¡æ‹Ÿ)"""
    new_prompt = copy.deepcopy(prompt)
    # --- å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨LLM APIæ¥å¯¹ä»»åŠ¡è¿›è¡Œé‡Šä¹‰ ---
    # æ¨¡æ‹Ÿå®ç°ï¼š
    new_prompt['task'] = f"[Paraphrased] {new_prompt['task']}"
    print("INFO: Performed paraphrase_task.")
    return new_prompt

def change_tone(prompt: dict) -> dict:
    """åŠ¨ä½œ2: æ”¹å˜è¯­æ°”/é£æ ¼"""
    new_prompt = copy.deepcopy(prompt)
    chosen_tone = random.choice(TONE_LIBRARY)
    new_prompt['task'] = f"{new_prompt['task']}, {chosen_tone}."
    print(f"INFO: Performed change_tone, added '{chosen_tone}'.")
    return new_prompt

def add_expert_role(prompt: dict) -> dict:
    """åŠ¨ä½œ3: å¢åŠ /ç»†åŒ–ä¸“å®¶è§’è‰²"""
    new_prompt = copy.deepcopy(prompt)
    chosen_role = random.choice(ROLE_LIBRARY)
    new_prompt['role'] = chosen_role
    print(f"INFO: Performed add_expert_role, set role to '{chosen_role}'.")
    return new_prompt

def add_constraint(prompt: dict) -> dict:
    """åŠ¨ä½œ4: æ·»åŠ çº¦æŸæ¡ä»¶"""
    new_prompt = copy.deepcopy(prompt)
    chosen_constraint = random.choice(CONSTRAINT_LIBRARY)
    if 'constraints' not in new_prompt:
        new_prompt['constraints'] = []
    new_prompt['constraints'].append(chosen_constraint)
    print(f"INFO: Performed add_constraint, added '{chosen_constraint}'.")
    return new_prompt

def add_few_shot_example(prompt: dict) -> dict:
    """åŠ¨ä½œ5: æ·»åŠ ç¤ºä¾‹"""
    new_prompt = copy.deepcopy(prompt)
    chosen_example = random.choice(EXAMPLE_LIBRARY)
    if 'examples' not in new_prompt:
        new_prompt['examples'] = []
    new_prompt['examples'].append(chosen_example)
    print(f"INFO: Performed add_few_shot_example, added an example.")
    return new_prompt

# ==============================================================================
# æ­¥éª¤ 3: åˆ›å»ºåŠ¨ä½œæ˜ å°„
# å°†æ•´æ•°ç´¢å¼•æ˜ å°„åˆ°æˆ‘ä»¬ä¸Šé¢å®šä¹‰çš„å‡½æ•°ã€‚RLä»£ç†å°†è¾“å‡ºè¿™ä¸ªç´¢å¼•ã€‚
# ==============================================================================

ACTION_MAP = {
    0: paraphrase_task,
    1: change_tone,
    2: add_expert_role,
    3: add_constraint,
    4: add_few_shot_example,
}

# ==============================================================================
# æ­¥éª¤ 4: ä¸»ç¨‹åº - æ¨¡æ‹ŸRLä»£ç†é€‰æ‹©å¹¶æ‰§è¡ŒåŠ¨ä½œ
# ==============================================================================
if __name__ == "__main__":
    # å‡è®¾è¿™æ˜¯æˆ‘ä»¬ä»ä¸»å¾ªç¯ä¸­å¾—åˆ°çš„ã€é™·å…¥å±€éƒ¨æœ€ä¼˜çš„æç¤ºè¯
    initial_structured_prompt = {
        "role": "You are a helpful assistant.",
        "task": "Classify the sentiment of the following text.",
        "constraints": ["The sentiment can be 'positive', 'negative', or 'neutral'."],
        "examples": []
    }

    print("="*50)
    print("ğŸš€ åŠ¨ä½œæ‰§è¡Œæ¨¡æ‹Ÿå¼€å§‹ ğŸš€")
    print("="*50)

    # æ¨¡æ‹Ÿæ‰§è¡Œ5æ¬¡ï¼Œæ¯æ¬¡éšæœºé€‰æ‹©ä¸€ä¸ªåŠ¨ä½œ
    for i in range(5):
        print(f"\n----------- Iteration {i+1} -----------")
        
        # --- æ¨¡æ‹ŸRLä»£ç†åšå‡ºé€‰æ‹© ---
        # å®é™…ä¸­ï¼Œè¿™ä¸ªç´¢å¼•æ˜¯ç”±RLç­–ç•¥ç½‘ç»œæ ¹æ®å½“å‰çŠ¶æ€é¢„æµ‹å¾—å‡ºçš„
        chosen_action_index = random.choice(list(ACTION_MAP.keys()))
        action_function = ACTION_MAP[chosen_action_index]
        
        print("\nğŸ“ åŸå§‹æç¤ºè¯:")
        print(initial_structured_prompt)
        
        print(f"\nğŸ¤– RLä»£ç†é€‰æ‹©çš„åŠ¨ä½œ: ({chosen_action_index}) -> {action_function.__name__}")
        
        # --- æ‰§è¡ŒåŠ¨ä½œ ---
        modified_prompt = action_function(initial_structured_prompt)
        
        print("\nâœ¨ ä¿®æ”¹åçš„æç¤ºè¯:")
        print(modified_prompt)
        
        # ä¸ºäº†ä¸‹ä¸€æ¬¡è¿­ä»£ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¿®æ”¹åçš„ç‰ˆæœ¬ä½œä¸ºæ–°çš„èµ·ç‚¹
        initial_structured_prompt = modified_prompt

    print("\n="*50)
    print("ğŸ æ¨¡æ‹Ÿç»“æŸ ğŸ")
    print("="*50)



import random
import copy
import hashlib

# ==============================================================================
# æ²¿ç”¨ä¹‹å‰çš„â€œåŠ¨ä½œâ€æ¨¡å—ä»£ç 
# ==============================================================================

ROLE_LIBRARY = [
    "You are a world-renowned historian specializing in the Renaissance.",
    "You are a cutting-edge astrophysicist from MIT.",
    "You are a Michelin 3-star chef with expertise in molecular gastronomy.",
    "You are a cynical but brilliant detective from a noir film."
]

CONSTRAINT_LIBRARY = [
    "Explain your reasoning step-by-step.",
    "The final answer must be a single paragraph.",
    "Avoid technical jargon and use simple language.",
    "Output the result in a JSON format."
]

def add_expert_role(prompt: dict) -> dict:
    new_prompt = copy.deepcopy(prompt)
    chosen_role = random.choice(ROLE_LIBRARY)
    new_prompt['role'] = chosen_role
    return new_prompt

def add_constraint(prompt: dict) -> dict:
    new_prompt = copy.deepcopy(prompt)
    chosen_constraint = random.choice(CONSTRAINT_LIBRARY)
    if 'constraints' not in new_prompt:
        new_prompt['constraints'] = []
    new_prompt['constraints'].append(chosen_constraint)
    return new_prompt

ACTION_MAP = {
    0: add_expert_role,
    1: add_constraint,
}

# ==============================================================================
# æ­¥éª¤ 1: æ¨¡æ‹Ÿé€‚åº”åº¦å‡½æ•° (Fitness Function)
# åœ¨æ‚¨çš„çœŸå®é¡¹ç›®ä¸­ï¼Œè¿™å°†æ˜¯æ‚¨å·²ç»æ‹¥æœ‰çš„ä¸»è¿­ä»£ç®—æ³•ä¸­çš„è¯„ä¼°éƒ¨åˆ†ã€‚
# ==============================================================================

def calculate_fitness(prompt: dict) -> float:
    """
    ä¸€ä¸ªæ¨¡æ‹Ÿçš„é€‚åº”åº¦è®¡ç®—å‡½æ•°ã€‚
    å®ƒä¼šæ ¹æ®æç¤ºè¯çš„å†…å®¹ç»™å‡ºä¸€ä¸ªâ€œåˆ†æ•°â€ã€‚
    ä¸ºäº†è®©æ¨¡æ‹Ÿæ›´çœŸå®ï¼š
    - è§’è‰²è¶Šå…·ä½“ï¼Œåˆ†æ•°è¶Šé«˜ã€‚
    - çº¦æŸè¶Šå¤šï¼Œåˆ†æ•°è¶Šé«˜ã€‚
    - æˆ‘ä»¬è¿˜åŠ å…¥ä¸€äº›éšæœºæ€§ï¼Œæ¨¡æ‹Ÿè¯„ä¼°ä¸­çš„å™ªå£°ã€‚
    """
    score = 0.5  # åŸºç¡€åˆ†

    # è§’è‰²è¶Šå…·ä½“ï¼Œå¾—åˆ†è¶Šé«˜
    if "assistant" not in prompt.get('role', ''):
        score += 0.25

    # çº¦æŸè¶Šå¤šï¼Œå¾—åˆ†è¶Šé«˜ï¼ˆä½†æœ‰ä¸Šé™ï¼‰
    score += min(0.2, len(prompt.get('constraints', [])) * 0.1)
    
    # åŠ å…¥åŸºäºå†…å®¹çš„å“ˆå¸Œå€¼ï¼Œè®©ç›¸åŒçš„promptå¾—åˆ†ç¨³å®šï¼Œä¸åŒçš„promptå¾—åˆ†ä¸åŒ
    prompt_string = str(prompt)
    hash_value = int(hashlib.md5(prompt_string.encode()).hexdigest(), 16)
    randomness = (hash_value % 100) / 1000.0 # äº§ç”Ÿä¸€ä¸ª-0.05åˆ°+0.05çš„ç¨³å®šå™ªå£°
    
    final_score = score + randomness
    
    return round(final_score, 4)

# ==============================================================================
# æ­¥éª¤ 2: å®ç°æ–¹æ¡ˆAçš„å¥–åŠ±è®¡ç®—å‡½æ•°
# ==============================================================================

def calculate_reward_plan_a(prompt_old: dict, prompt_new: dict) -> tuple[float, float, float]:
    """
    æ ¹æ®æ–¹æ¡ˆAï¼ˆç›´æ¥å¥–åŠ±ï¼‰è®¡ç®—å¥–åŠ±ã€‚

    Args:
        prompt_old (dict): ä¿®æ”¹å‰çš„æç¤ºè¯ã€‚
        prompt_new (dict): ä¿®æ”¹åçš„æç¤ºè¯ã€‚

    Returns:
        tuple[float, float, float]: (æ–°é€‚åº”åº¦, æ—§é€‚åº”åº¦, æœ€ç»ˆå¥–åŠ±)
    """
    # è¯„ä¼°æ—§æç¤ºè¯çš„é€‚åº”åº¦
    fitness_old = calculate_fitness(prompt_old)

    # è¯„ä¼°æ–°æç¤ºè¯çš„é€‚åº”åº¦
    fitness_new = calculate_fitness(prompt_new)

    # å¥–åŠ± = æ–°é€‚åº”åº¦ - æ—§é€‚åº”åº¦
    reward = fitness_new - fitness_old

    return fitness_new, fitness_old, round(reward, 4)

# ==============================================================================
# æ­¥éª¤ 3: ä¸»ç¨‹åº - å®Œæ•´æµç¨‹æ¨¡æ‹Ÿ
# ==============================================================================
if __name__ == "__main__":
    # è®¾å®šä¸€ä¸ªåˆå§‹çš„ã€æœ‰å¾…ä¼˜åŒ–çš„æç¤ºè¯
    current_prompt = {
        "role": "You are a helpful assistant.",
        "task": "Explain what a neural network is.",
        "constraints": []
    }

    print("="*60)
    print("ğŸš€ å¼ºåŒ–å­¦ä¹ å¾ªç¯æ¨¡æ‹Ÿå¼€å§‹ (æ–¹æ¡ˆA: ç›´æ¥å¥–åŠ±) ğŸš€")
    print("="*60)

    # æ¨¡æ‹Ÿè¿è¡Œ5æ¬¡è¿­ä»£
    for i in range(5):
        print(f"\n----------- Iteration {i+1} -----------")

        # 1. éšæœºé€‰æ‹©ä¸€ä¸ªåŠ¨ä½œæ¥ä¿®æ”¹å½“å‰æç¤ºè¯
        chosen_action_index = random.choice(list(ACTION_MAP.keys()))
        action_function = ACTION_MAP[chosen_action_index]
        
        print(f"å½“å‰æç¤ºè¯: {current_prompt}")
        print(f"ğŸ¤– é€‰æ‹©åŠ¨ä½œ: {action_function.__name__}")
        
        # 2. æ‰§è¡ŒåŠ¨ä½œï¼Œç”Ÿæˆæ–°æç¤ºè¯
        new_prompt = action_function(current_prompt)
        print(f"ç”Ÿæˆçš„æ–°æç¤ºè¯: {new_prompt}")

        # 3. è®¡ç®—å¥–åŠ±
        f_new, f_old, calculated_reward = calculate_reward_plan_a(current_prompt, new_prompt)

        print("-" * 20)
        print(f"ğŸ“Š é€‚åº”åº¦è¯„ä¼°:")
        print(f"  - æ—§æç¤ºè¯é€‚åº”åº¦ (Fitness_old): {f_old}")
        print(f"  - æ–°æç¤ºè¯é€‚åº”åº¦ (Fitness_new): {f_new}")
        print("-" * 20)
        
        if calculated_reward > 0:
            print(f"ğŸ’° è®¡ç®—å¥–åŠ±: {calculated_reward}  (è¿™æ˜¯ä¸€ä¸ªç§¯æå¥–åŠ± ğŸ‘)")
            # å¦‚æœåŠ¨ä½œäº§ç”Ÿäº†ç§¯ææ•ˆæœï¼Œæˆ‘ä»¬å°±é‡‡çº³è¿™ä¸ªæ–°æç¤ºè¯
            current_prompt = new_prompt
        elif calculated_reward < 0:
            print(f"ğŸ’° è®¡ç®—å¥–åŠ±: {calculated_reward}  (è¿™æ˜¯ä¸€ä¸ªæ¶ˆæå¥–åŠ± ğŸ‘)")
            # å¦‚æœæ˜¯æ¶ˆææ•ˆæœï¼Œæˆ‘ä»¬ä¿ç•™åŸæç¤ºè¯ï¼ˆåœ¨çœŸå®RLä¸­ï¼Œè¿™æ¬¡ç»å†ä¾ç„¶ä¼šè¢«å­¦ä¹ ï¼‰
        else:
            print(f"ğŸ’° è®¡ç®—å¥–åŠ±: {calculated_reward}  (æ— å˜åŒ–)")
    
    print("\n="*60)
    print("ğŸ æ¨¡æ‹Ÿç»“æŸ ğŸ")
    print("="*60)
