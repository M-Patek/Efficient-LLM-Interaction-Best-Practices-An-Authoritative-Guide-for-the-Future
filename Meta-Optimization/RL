# -*- coding: utf-8 -*-

# ==============================================================================
# æ­¥éª¤ 0: å®‰è£…å’Œå¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
# å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£…è¿™äº›åº“ï¼Œè¯·å…ˆè¿è¡Œè¿™è¡Œå‘½ä»¤:
# pip install sentence-transformers numpy torch
# ==============================================================================
import numpy as np
from sentence_transformers import SentenceTransformer
import random
import copy
import hashlib
import json # ç”¨äºç¾åŒ–æ‰“å°è¾“å‡º

print("æ­£åœ¨åŠ è½½ SentenceTransformer æ¨¡å‹...")
# 'all-MiniLM-L6-v2' æ˜¯ä¸€ä¸ªè½»é‡ä¸”é«˜æ•ˆçš„æ¨¡å‹ï¼Œè¾“å‡º384ç»´å‘é‡
# è¿™ä¸ªè¿‡ç¨‹å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼Œä½†æ•´ä¸ªç¨‹åºåªéœ€è¦åŠ è½½ä¸€æ¬¡
ENCODER_MODEL = SentenceTransformer('all-MiniLM-L6-v2')
print("æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚")
print("=" * 60)


# ==============================================================================
# æ¨¡å— A: åŠ¨ä½œç©ºé—´ (Action Space)
# å®šä¹‰äº†RLæ™ºèƒ½ä½“å¯ä»¥æ‰§è¡Œçš„æ‰€æœ‰ä¿®æ”¹æç¤ºè¯çš„åŠ¨ä½œã€‚
# ==============================================================================

# --- åŠ¨ä½œç´ æåº“ ---
ROLE_LIBRARY = [
    "You are a world-renowned historian specializing in the Renaissance.",
    "You are a cutting-edge astrophysicist from MIT.",
    "You are a Michelin 3-star chef with expertise in molecular gastronomy.",
    "You are a cynical but brilliant detective from a noir film."
]
CONSTRAINT_LIBRARY = [
    "Explain your reasoning step-by-step.",
    "The final answer must be a single paragraph.",
    "Avoid technical jargon and use simple language.",
    "Output the result in a JSON format with keys 'item' and 'description'.",
    "Do not mention your own identity as an AI model."
]
EXAMPLE_LIBRARY = [
    {"input": "Company: Apple Inc.", "output": "Industry: Technology"},
    {"input": "Company: Toyota", "output": "Industry: Automotive"}
]
TONE_LIBRARY = [
    "in a formal and professional tone",
    "in a friendly and conversational tone",
    "in a witty and slightly sarcastic tone",
    "in a way that a complete beginner can understand"
]

# --- å…·ä½“çš„åŠ¨ä½œå‡½æ•° ---
def paraphrase_task(prompt: dict) -> dict:
    """åŠ¨ä½œ0: æ ¸å¿ƒä»»åŠ¡é‡Šä¹‰ (æ¨¡æ‹Ÿ)"""
    new_prompt = copy.deepcopy(prompt)
    # å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨LLM APIæ¥å¯¹ä»»åŠ¡è¿›è¡Œé‡Šä¹‰
    new_prompt['task'] = f"[Paraphrased] {new_prompt['task']}"
    return new_prompt

def change_tone(prompt: dict) -> dict:
    """åŠ¨ä½œ1: æ”¹å˜è¯­æ°”/é£æ ¼"""
    new_prompt = copy.deepcopy(prompt)
    chosen_tone = random.choice(TONE_LIBRARY)
    new_prompt['task'] = f"{new_prompt['task']}, {chosen_tone}."
    return new_prompt

def add_expert_role(prompt: dict) -> dict:
    """åŠ¨ä½œ2: å¢åŠ /ç»†åŒ–ä¸“å®¶è§’è‰²"""
    new_prompt = copy.deepcopy(prompt)
    new_prompt['role'] = random.choice(ROLE_LIBRARY)
    return new_prompt

def add_constraint(prompt: dict) -> dict:
    """åŠ¨ä½œ3: æ·»åŠ çº¦æŸæ¡ä»¶"""
    new_prompt = copy.deepcopy(prompt)
    new_prompt.setdefault('constraints', []).append(random.choice(CONSTRAINT_LIBRARY))
    return new_prompt

def add_few_shot_example(prompt: dict) -> dict:
    """åŠ¨ä½œ4: æ·»åŠ ç¤ºä¾‹"""
    new_prompt = copy.deepcopy(prompt)
    new_prompt.setdefault('examples', []).append(random.choice(EXAMPLE_LIBRARY))
    return new_prompt

# --- åŠ¨ä½œæ˜ å°„è¡¨ ---
# å°†æ•´æ•°ç´¢å¼•æ˜ å°„åˆ°åŠ¨ä½œå‡½æ•°ï¼ŒRLæ™ºèƒ½ä½“é€šè¿‡è¾“å‡ºæ•´æ•°æ¥é€‰æ‹©åŠ¨ä½œã€‚
ACTION_MAP = {
    0: paraphrase_task,
    1: change_tone,
    2: add_expert_role,
    3: add_constraint,
    4: add_few_shot_example,
}


# ==============================================================================
# æ¨¡å— B: çŠ¶æ€è¡¨å¾ (State Representation)
# å®šä¹‰äº†å¦‚ä½•å°†æ–‡æœ¬æç¤ºè¯å’Œå…ƒæ•°æ®è½¬æ¢ä¸ºRLæ™ºèƒ½ä½“èƒ½ç†è§£çš„æ•°å­—å‘é‡ã€‚
# ==============================================================================

def parse_prompt(raw_prompt: str) -> dict:
    """
    ç®€åŒ–çš„è§£æå‡½æ•°ï¼Œå°†åŸå§‹æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–å­—å…¸ã€‚
    åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™ä¸€æ­¥å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æé€»è¾‘ã€‚
    ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å‡è®¾å®ƒå¯ä»¥ä»ä¸€ä¸ªå›ºå®šçš„ç»“æ„ä¸­è§£æã€‚
    """
    # è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå®é™…å¾ªç¯ä¸­æˆ‘ä»¬å°†ç›´æ¥ä½¿ç”¨ç»“æ„åŒ–å­—å…¸ã€‚
    return {
        "role": "ä½ æ˜¯ä¸€åèµ„æ·±è¥é”€æ–‡æ¡ˆã€‚",
        "task": "ä¸ºä¸€æ¬¾åä¸ºâ€˜æ˜Ÿå°˜å’–å•¡â€™çš„æ–°å“å†™ä¸‰æ¡å®£ä¼ æ ‡è¯­ã€‚",
        "constraints": ["æ¯æ¡ä¸è¶…è¿‡15ä¸ªå­—", "é£æ ¼è¦æ–‡è‰ºä¸”æœ‰æƒ³è±¡åŠ›"],
        "examples": [],
        "format": ""
    }

def reconstruct_prompt_to_raw(structured_prompt: dict) -> str:
    """å°†ç»“æ„åŒ–å­—å…¸é‡æ–°ç»„åˆæˆä¸€ä¸ªåŸå§‹å­—ç¬¦ä¸²ï¼Œç”¨äºå‘é‡åŒ–ã€‚"""
    parts = []
    if structured_prompt.get('role'):
        parts.append(structured_prompt['role'])
    if structured_prompt.get('task'):
        parts.append(structured_prompt['task'])
    if structured_prompt.get('constraints'):
        parts.append("Constraints: " + ", ".join(structured_prompt['constraints']))
    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å¯¹exampleså’Œformatçš„å¤„ç†
    return " ".join(parts)


def create_state_vector(structured_prompt: dict, metadata: dict) -> np.ndarray:
    """
    å°†ç»“æ„åŒ–æç¤ºè¯å’Œå…ƒæ•°æ®è½¬æ¢ä¸ºä¸€ä¸ªå®Œæ•´çš„çŠ¶æ€å‘é‡ã€‚
    """
    embedding_dim = ENCODER_MODEL.get_sentence_embedding_dimension()

    # 1. ç‹¬ç«‹ç¼–ç æ–‡æœ¬éƒ¨åˆ†
    role_vector = ENCODER_MODEL.encode(structured_prompt.get('role', ''))
    task_vector = ENCODER_MODEL.encode(structured_prompt.get('task', ''))

    if structured_prompt.get('constraints'):
        constraint_vectors = ENCODER_MODEL.encode(structured_prompt['constraints'])
        avg_constraint_vector = np.mean(constraint_vectors, axis=0)
    else:
        avg_constraint_vector = np.zeros(embedding_dim)

    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾exampleså’Œformatä¸ºç©º
    avg_example_vector = np.zeros(embedding_dim)
    format_vector = np.zeros(embedding_dim)

    # 2. æå–å¹¶è§„èŒƒåŒ–ä¸Šä¸‹æ–‡ç‰¹å¾
    # æ³¨æ„ï¼šåœ¨å®é™…è®­ç»ƒä¸­ï¼Œè¿™äº›æ•°å€¼ç‰¹å¾åº”è¯¥è¢«è§„èŒƒåŒ–ï¼ˆä¾‹å¦‚ç¼©æ”¾åˆ°0-1èŒƒå›´ï¼‰
    context_feature_vector = np.array([
        metadata.get('fitness', 0.0),
        len(reconstruct_prompt_to_raw(structured_prompt)), # ä½¿ç”¨å­—ç¬¦æ•°ä½œä¸ºtoken_countçš„ä»£ç†
        len(structured_prompt.get('constraints', [])),
        metadata.get('iterations_stuck', 0)
    ])

    # 3. æ‹¼æ¥æ‰€æœ‰éƒ¨åˆ†ï¼Œå½¢æˆæœ€ç»ˆçŠ¶æ€å‘é‡
    return np.concatenate([
        role_vector, task_vector, avg_constraint_vector,
        avg_example_vector, format_vector, context_feature_vector
    ])


# ==============================================================================
# æ¨¡å— C: å¥–åŠ±è®¡ç®— (Reward Calculation)
# å®šä¹‰äº†å¦‚ä½•è¯„ä¼°ä¸€ä¸ªåŠ¨ä½œçš„å¥½åã€‚
# ==============================================================================

def calculate_fitness(prompt: dict) -> float:
    """
    ä¸€ä¸ªæ¨¡æ‹Ÿçš„é€‚åº”åº¦è®¡ç®—å‡½æ•°ã€‚å®ƒæ ¹æ®æç¤ºè¯çš„å†…å®¹ç»™å‡ºä¸€ä¸ªâ€œåˆ†æ•°â€ã€‚
    - è§’è‰²è¶Šå…·ä½“ï¼Œåˆ†æ•°è¶Šé«˜ã€‚
    - çº¦æŸè¶Šå¤šï¼Œåˆ†æ•°è¶Šé«˜ã€‚
    - åŠ å…¥åŸºäºå†…å®¹çš„å“ˆå¸Œå€¼ï¼Œè®©ç›¸åŒçš„promptå¾—åˆ†ç¨³å®šï¼Œæ¨¡æ‹Ÿè¯„ä¼°ä¸­çš„ç¡®å®šæ€§å™ªå£°ã€‚
    """
    score = 0.5  # åŸºç¡€åˆ†
    if "assistant" not in prompt.get('role', ''):
        score += 0.25 # å…·ä½“è§’è‰²åŠ åˆ†
    score += min(0.2, len(prompt.get('constraints', [])) * 0.1) # çº¦æŸåŠ åˆ†

    # åŠ å…¥åŸºäºå†…å®¹çš„å“ˆå¸Œå€¼ï¼Œè®©åˆ†æ•°å¯¹äºç›¸åŒè¾“å…¥æ˜¯ç¡®å®šçš„
    prompt_string = json.dumps(prompt, sort_keys=True)
    hash_value = int(hashlib.md5(prompt_string.encode()).hexdigest(), 16)
    randomness = (hash_value % 100) / 1000.0 # äº§ç”Ÿä¸€ä¸ª-0.05åˆ°+0.05çš„ç¨³å®šå™ªå£°
    
    return round(score + randomness, 4)

def calculate_reward(prompt_old: dict, prompt_new: dict) -> tuple[float, float, float]:
    """
    å¥–åŠ± = æ–°é€‚åº”åº¦ - æ—§é€‚åº”åº¦ã€‚
    æ­£å¥–åŠ±è¡¨ç¤ºæå‡ï¼Œè´Ÿå¥–åŠ±è¡¨ç¤ºä¸‹é™ã€‚
    """
    fitness_old = calculate_fitness(prompt_old)
    fitness_new = calculate_fitness(prompt_new)
    reward = fitness_new - fitness_old
    return fitness_new, fitness_old, round(reward, 4)

# ==============================================================================
# æœ€ç»ˆæ•´åˆï¼šæ¨¡æ‹Ÿå®Œæ•´çš„RLä¼˜åŒ–å¾ªç¯
# ==============================================================================
if __name__ == "__main__":
    # --- åˆå§‹åŒ–ç¯å¢ƒ ---
    # è®¾å®šä¸€ä¸ªåˆå§‹çš„ã€æœ‰å¾…ä¼˜åŒ–çš„æç¤ºè¯
    current_prompt = {
        "role": "You are a helpful assistant.",
        "task": "Explain what a neural network is.",
        "constraints": []
    }
    # åˆå§‹åŒ–å…ƒæ•°æ®
    current_metadata = {
        "fitness": calculate_fitness(current_prompt),
        "iterations_stuck": 0
    }

    print("ğŸš€ å¼ºåŒ–å­¦ä¹ å¾ªç¯æ¨¡æ‹Ÿå¼€å§‹ ğŸš€")
    print("=" * 60)
    print(f"åˆå§‹æç¤ºè¯: \n{json.dumps(current_prompt, indent=2)}")
    print(f"åˆå§‹é€‚åº”åº¦: {current_metadata['fitness']}")
    print("=" * 60)

    # æ¨¡æ‹Ÿè¿è¡Œ10æ¬¡è¿­ä»£
    for i in range(10):
        print(f"\n----------- Iteration {i+1} -----------")

        # 1.ã€çŠ¶æ€ã€‘è§‚å¯Ÿå½“å‰ç¯å¢ƒï¼Œç”ŸæˆçŠ¶æ€å‘é‡
        print("1. [çŠ¶æ€ S] æ­£åœ¨ç”Ÿæˆå½“å‰çŠ¶æ€çš„å‘é‡è¡¨ç¤º...")
        state_vector = create_state_vector(current_prompt, current_metadata)
        print(f"   - ç”ŸæˆçŠ¶æ€å‘é‡ï¼Œç»´åº¦: {state_vector.shape}")
        # (åœ¨çœŸå®çš„RLä¸­ï¼Œè¿™ä¸ªå‘é‡ä¼šè¾“å…¥åˆ°ç­–ç•¥ç½‘ç»œä¸­)

        # 2.ã€åŠ¨ä½œã€‘RLæ™ºèƒ½ä½“æ ¹æ®çŠ¶æ€é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œ
        # (æ­¤å¤„ä¸ºæ¨¡æ‹Ÿï¼Œå› æ­¤æˆ‘ä»¬éšæœºé€‰æ‹©ä¸€ä¸ªåŠ¨ä½œ)
        chosen_action_index = random.choice(list(ACTION_MAP.keys()))
        action_function = ACTION_MAP[chosen_action_index]
        print(f"2. [åŠ¨ä½œ A] æ™ºèƒ½ä½“é€‰æ‹©åŠ¨ä½œ: ({chosen_action_index}) -> {action_function.__name__}")

        # 3.ã€æ‰§è¡Œã€‘æ‰§è¡ŒåŠ¨ä½œï¼Œç”Ÿæˆæ–°æç¤ºè¯
        new_prompt = action_function(current_prompt)
        print(f"3. [æ‰§è¡Œ] ç”Ÿæˆçš„æ–°æç¤ºè¯: \n{json.dumps(new_prompt, indent=2)}")

        # 4.ã€å¥–åŠ±ã€‘è®¡ç®—æ‰§è¡Œè¯¥åŠ¨ä½œåè·å¾—çš„å¥–åŠ±
        f_new, f_old, calculated_reward = calculate_reward(current_prompt, new_prompt)
        print("4. [å¥–åŠ± R] æ­£åœ¨è®¡ç®—å¥–åŠ±...")
        print(f"   - æ—§æç¤ºè¯é€‚åº”åº¦: {f_old}")
        print(f"   - æ–°æç¤ºè¯é€‚åº”åº¦: {f_new}")
        
        # 5.ã€çŠ¶æ€è½¬ç§»ã€‘æ ¹æ®å¥–åŠ±æ›´æ–°çŠ¶æ€
        print("5. [çŠ¶æ€è½¬ç§» S'] æ­£åœ¨æ›´æ–°çŠ¶æ€...")
        if calculated_reward > 0:
            print(f"   - å¥–åŠ±ä¸ºæ­£ ({calculated_reward:.4f}) ğŸ‘ï¼Œé‡‡çº³æ–°æç¤ºè¯ï¼")
            current_prompt = new_prompt
            current_metadata['fitness'] = f_new
            current_metadata['iterations_stuck'] = 0
        else:
            print(f"   - å¥–åŠ±ä¸ºè´Ÿæˆ–é›¶ ({calculated_reward:.4f}) ğŸ‘ï¼Œä¿ç•™åŸæç¤ºè¯ã€‚")
            # é€‚åº”åº¦ä¿æŒä¸å˜
            current_metadata['iterations_stuck'] += 1
        
        print(f"   - å½“å‰å¡ä½è½®æ•°: {current_metadata['iterations_stuck']}")
        # (åœ¨çœŸå®çš„RLä¸­ï¼Œ(S, A, R, S') è¿™ä¸ªå®Œæ•´çš„ç»å†å…ƒç»„ä¼šè¢«å­˜å…¥ç»éªŒå›æ”¾æ± ç”¨äºè®­ç»ƒ)

    print("\n="*60)
    print("ğŸ æ¨¡æ‹Ÿç»“æŸ ğŸ")
    print("="*60)
    print(f"æœ€ç»ˆä¼˜åŒ–åçš„æç¤ºè¯: \n{json.dumps(current_prompt, indent=2)}")
    print(f"æœ€ç»ˆé€‚åº”åº¦: {current_metadata['fitness']}")
